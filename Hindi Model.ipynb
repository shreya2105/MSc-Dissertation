{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from indicnlp import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_tweets = pd.read_csv(\"hindilabelled.csv\")\n",
    "#hindi_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anti_CAA    17575\n",
       "Pro_CAA     16060\n",
       "Neutral      2470\n",
       "Name: CAA_stance, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_tweets['CAA_stance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from indic_transliteration import sanscript\n",
    "#from indic_transliteration.sanscript import SchemeMap, SCHEMES, transliterate\n",
    "\n",
    "\n",
    "#print(transliterate(data, sanscript.ITRANS, sanscript.DEVANAGARI))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hindi_tweets[\"text\"] = hindi_tweets[\"text\"].map(lambda x: transliterate(x, sanscript.ITRANS, sanscript.DEVANAGARI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_twee = hindi_tweets[hindi_tweets[\"CAA_stance\"].notnull()]\n",
    "\n",
    "import numpy as np\n",
    "from random import sample\n",
    "\n",
    "#np.random.shuffle(hindi_twee.values)\n",
    "\n",
    "hindi_tweet = hindi_twee[:int((len(hindi_twee)+1)*.30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pro_CAA     5721\n",
       "Anti_CAA    2912\n",
       "Neutral     2198\n",
       "Name: CAA_stance, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_tweet['CAA_stance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "col = ['CAA_stance', 'text']\n",
    "hindi_tweet1 = hindi_tweet[col]\n",
    "hindi_tweet1 = hindi_tweet1[pd.notnull(hindi_tweet1['text'])]\n",
    "hindi_tweet1.columns = ['CAA_stance', 'text']\n",
    "hindi_tweet1['stance_id'] = hindi_tweet1['CAA_stance'].factorize()[0]\n",
    "stance_id_df = hindi_tweet1[['CAA_stance', 'stance_id']].drop_duplicates().sort_values('stance_id')\n",
    "stance_to_id = dict(stance_id_df.values)\n",
    "id_to_stance = dict(stance_id_df[['stance_id', 'CAA_stance']].values)\n",
    "#hindi_tweet1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = pd.read_csv(\"final_stopwords.txt\", names=['words'])\n",
    "hieng = pd.read_csv(\"hinglish_stopwords.txt\", names = ['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = hi['words'].to_list()\n",
    "hieng = hieng['words'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "final_stopwords_list = hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyaagarwal/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['अथव', 'अध', 'अन', 'अपन', 'अभ', 'आग', 'आद', 'आपक', 'इत', 'इनक', 'इसक', 'इसम', 'इसल', 'उनक', 'उसक', 'एव', 'ऐस', 'कभ', 'करत', 'करन', 'कह', 'कहत', 'गय', 'जबक', 'जर', 'जह', 'झक', 'तथ', 'तन', 'तर', 'दर', 'धर', 'नस', 'पड', 'पहल', 'बड', 'बन', 'बह', 'यत', 'यद', 'यम', 'रख', 'रत', 'रह', 'रहत', 'लक', 'वय', 'वर', 'वग़', 'सक', 'सकत', 'सभ', 'सम', 'सर', 'सस', 'हमन', 'हर'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10831, 5274)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf = True, min_df = 5, norm ='l2', encoding='ISCII', ngram_range=(1, 2), stop_words = final_stopwords_list)\n",
    "features = tfidf.fit_transform(hindi_tweet1.text).toarray()\n",
    "labels = hindi_tweet1.stance_id\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import word_tokenize    \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = LinearSVC()\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, hindi_tweet1.index, test_size=0.33, random_state=0)\n",
    "\n",
    "clf = model.fit(X_train, y_train)\n",
    "scores = cross_val_score(clf, X_test, y_test, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83776224 0.81958042 0.83356643 0.80839161 0.85314685]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_modelhindi.sav'\n",
    "pickle.dump(model, open(filename, 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = loaded_model.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Pro_CAA       0.87      0.89      0.88      1890\n",
      "    Anti_CAA       0.78      0.74      0.76       971\n",
      "     Neutral       0.91      0.92      0.91       714\n",
      "\n",
      "    accuracy                           0.86      3575\n",
      "   macro avg       0.85      0.85      0.85      3575\n",
      "weighted avg       0.85      0.86      0.86      3575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    " \n",
    "print (classification_report(y_test, model.predict(X_test), target_names=['Pro_CAA', 'Anti_CAA', 'Neutral']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83926, 10)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(hindi_tweet.columns.values)\n",
    "i1 = hindi_tweets.set_index(keys).index\n",
    "i2 = hindi_twee.set_index(keys).index\n",
    "tobelabelled = hindi_tweets[~i1.isin(i2)]\n",
    "tobelabelled.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = tfidf.transform(tobelabelled.text)\n",
    "x_new = x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyaagarwal/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tobelabelled[\"CAA_stance\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [tobelabelled, hindi_twee]\n",
    "hi_tweets = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"/Users/shreyaagarwal/Google Drive/Dissertation/Data/hindilabelled_1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_tweets.to_csv(file_name, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           35956\n",
       "2           26374\n",
       "1           21596\n",
       "Anti_CAA    17575\n",
       "Pro_CAA     16060\n",
       "Neutral      2470\n",
       "Name: CAA_stance, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_tweets[\"CAA_stance\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
