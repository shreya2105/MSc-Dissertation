---
title: "CAA_Analysis"
author: "SA"
date: "6/23/2020"
output: html_document
---

```{r}
library(tidyverse)
library(data.table)
library(quanteda)
library(stringr)
library(lubridate)

```

Read the data and filter unrequired columns 
```{r}
caa_dataset <- fread("/Users/shreyaagarwal/Google Drive/Dissertation/Data/unique_rows_hi_eng.csv")

caa_dataset <- caa_dataset[,-c(1,2)]

colnames(caa_dataset)
#filter down to relevant columns
caa_text <- caa_dataset %>% select("created_at","screen_name","text","hashtags", "source", "description", "lang")
caa_text$created_at <- lubridate::as_date(caa_text$created_at)

#hashtag table
hashtags <- as.data.table(table(caa_dataset$hashtags))
```

Word lists for columns - hashtags, description, screen_name
- assign hashtags to Pro CAA, Anti CAA and Neutral stance
```{r}
#Str_detect
anti_caa <- c("WeReject_CAA_NPR_NRC", "IndiaAgainstCAA_NRC", "notocaa", "kagaj_nahi_dikhayenge", "Anti_CAA","शाहीनबाग_जीतेगा_मोदी_हारेगा","UNRejectsCAA","IndiaAgainstCAA","AmitShahIstifaDo","RejectCAA","IndiaAgainstCAA_NRC_NPR","ArrestKapilMishra","SCSTOBC_Against_Hate", "CrimesAgainstHumanity","HinduTerror")

pro_caa <- c("CAA_NRC_support","SupportCAA" ,"supportCAA", "IndiaSupportsCAA_NRC", "Pro_CAA", "शाहीन_बाग_हारेगा_देश_जितेंगा","IAmIndianISupportCAA","IStandWithKapilMishra","SaveDelhiHindus","हिंदुओ_को_मारना_बंद_करो",
"ISupportKapilMishra","हर_दिल_में_योगी","PatrioticIndiansSupportCAA","AntiHinduRI", "Anti CAA agitators killed", "Tahir_hussain_terrorist", "ISupportKapilMishra")

neutral_hashtags <- c("DelhiRiots2020", "CAA", "ShaheenBagh", "CAA_NRC", "DelhiViolance", "Delhigenocide", "Jafrabad", "CitizenshipAmendmentBill", "ShaheenBaghProtests", "DelhiCAAClashes", "CAAProtests", "CAAProtest", "CitizenshipAmendmentAct", "DelhiBurning", "CitizenshipAmendmentBill2019", "CitizenshipAct", "caa", "shaheenbaghs","DelhiPolice", "Kashmir", "AmulyaLeona", "Karnataka", "Aligarh")

n_hash <- ("DelhiRiots2020 | CAA | ShaheenBagh |CAA_NRC|DelhiViolance|Delhigenocide|Jafrabad|CitizenshipAmendmentBill|ShaheenBaghProtests|DelhiCAAClashes|CAAProtests|CAAProtest| CitizenshipAmendmentAct|DelhiBurning|CitizenshipAmendmentBill2019|CitizenshipAct|caa|shaheenbaghs")

news_words <- ("Breaking news | latest news | independent news | Hindi News | digital news | news agency | leading news | online news | Kadak news | News Services | news follow | AJ+ is news |daily news | presenting news |news agency | Regional news | Asianetnews | international news |news channel| source on news| global news | news ticker | commentary news | Deccan Chronicle | Democracy Express | instant news | The Economic Times| Indian news | FinancialExpress | word in news | news website | news")
```

#Excluded Screen Names from news org tweets dataset
```{r}
ind_screen_name <- ("_cricketkeeda|AnOpenLetter001 |asadr3855|dailynewsteller|fakingnews|FarooqmoinMoin|ReporterAnkitG|asadr3855|Zebaism|PratibaRaman|pallavict|HighJoshPD|Diya_BJPLover|PeepingMoon|abhishekdey04|ashokhajeri|misrashutosh|SirajMumin|ArunKumar7997|mahuatar|Deepika81682230|Kanishka183|Yogendr89778547|brainy_indian|HEYRAM65860375|Hindinewsguru|mr_rebel_amir|real_hindu1|xxSachinx|vishnur_otn|vijaykjha|very_politickle|tmanipalj|ThrillingTalha|thodappakattai|THEPANIPURI|thechikku|tantry_b|SyedAliHassanK4|sumtweets08|SubhashDaga59|StillAliveRicha|SRIDHAR0520|shivkishore81|shinjinidb|SANJAYTRIKA|SaintMuneesh|Roshan575002|RishikaSadam|RishabhEIN|real_Deepipika|real_Deepika_|rankraiser|pakco_updates|pandithariojha|paromita0611|pinakaSharanga|Ppriyacee|prabodhmhalgi|pratikbTOI|PreetiV70305055|PyckerKollywood|radhikabajaj|RahulSi60262144|Manankmr|manish_media|MensDayOutIndia|MeraNewsHindi|MNNewsLive|mohitchandrave1|mohitk_912|Ms_jodha|MyEsportsGlobe|mynews2020|nadircazi|nationalwmedia|NationFirst__|navdeepkesari|NewstoLive1|nimo_new|nirmalsingh1606|Niteshjumbo|nivie|old_india|OmanObserver|opednews|Ozaaer|p_vineeta|manish_media|_chaoticsaint_|_Its_Raj|_KAFAWA_|_soumyajit37|AAPExpress|AbdulMoid07|abhaykumarjnu|abhijitsingh18|AbhinandanSekhr|abhisheksinghpu|abhishekvats29|Abid_ali_uot|AggarwalSagar|AishaOluseye|AjayMeethale|ajkitaazakhabar|akfromindia|AkhbareMashriq1|akwaghmare|AllTheNewsIndia|AlokAryaveer|alternatekash|ameyamjoshi|amitghoshspeaks|amitgo|amitmaulviya|ammy263|amritananda_c|amustnews|AnantaAdhikar18|Andhra_Wishesh|AnilkumarAKM|anjalitiwari339|anjn|AppleheadWendy|ARUNSHARMAJI|AsgardianL0ki|ashokb56|ashokmuscat|AsiaDespatch|AsopaVinay|ASRNews1|atulr85|atwittiernil|AU_VaranasiNews|AvinashBharat2|ayushpandey49|balunair99|Bangladesh2day|BetaDroidIndia|betechs1|bgohil76|BHEnglish|bihaarkesari|bjp4fakenews|BonySen|BougtebMedia|CarlottaMohamed|CensoredToday|chalotweetkaro|charlesbhardwaj|ChhattisgarhThe|chinraj123|ChukkuNews|city_bollywood|ConnectionsCrat|CricketNDTV|curious_scribe|d1p70|Damn30704092|Deborahcox_caye|DeepkiranC|palakshahJourno|parikshit1012|PunjabiAngry|quickclarity|r_verma|ravapk|ReportHinduphob|nehaPatsariya|T04795327|TCP241|thehftprods|TheHinduCinema|Truenewsindia|Unknown14973713|vineetanews|bidyutchowdhury|FDikhana|Gyan_p_mishra|HatelaPappu|HimachalW|HindiFilmibeat|iamaashmehta|IndiLeak|jadoonjavedkhan|mytentaran|NahiChalegi|NCRKHABAR|Nguptaprakash|Rajeev_real|reports_india|sahiljoshii|Sanki_Tanashah|sniffthenews|the_newsvilla|TheViewsVoices|TimesMedia24hi|TOITopStories|YoungBhartiya|aajkitajakhabar|Ananyati|AnIdiotNature|AnkitMo61306367|BBN_India|BiharManthan|Engineer_Rahul1|Fatima_Z0hra|hindu_daily|LiveInqilab|lnnindia|mataonline|priyalovesnikon|Deshbhakt_NRI|desiblab|DevjyotGhoshal|Fakhrealam00786|GaurVatsala|gooner_neg|GreyFrost|hebdomedallic|Mango_News|N21chak|insidestoryind1|vaibhav8510|SamKhan999|sauravyadav1133|WORLDNEWSLAND1|Ishaqshk|mistbag|temurdur|theaerogram|thegreenhopes1|thepointout|tohidivity|Univrslfeelings|vigmukesh|vijaykjha|vishalnbt|whoizslmn|withcongresswb|WriterUnknow|XeroGround|yadavashutosh49|YAHHHKNOWWHAT|ZaqsPolitics|zohebkhan2|_Indiaupdates|_whatsinthenews|AbhiAvyakt|abhikhabartak|abhishe72539882|AbhiyaanChhapa|abntelugutv|aditisundan|alka1aug|alokverma1969|amit_trehan04|AmitKPalit|AnOpenLetter001|aparnaAD2|ApVeng|bhanujoshi01|Danny_deepz|DelReporter|deveshkumarbjp|dhairyam14|Dj_Cynical|DrAmol27|nishthasingh_13|aaliyagoyel1|nishant9717|MohammadSarva20|mann1043|Khabribhai1|karthikk_h|journalistHari|devsonukaushik|CholericCleric|bhavikgandhi_bg|ashfaqueamber|YadavPkjyadav|ellahi_ARY|ratnabhushanET|RaviPan31012457|real_Deepika_|RefMigrUpdate|sajidah_yousuf|sardesairajdeep|SarkDeb|scareme23|shanksnews|shindeckant|shivkishore81|shuklavivek92|siad_eng|SikheJane|singhshelleyET|snapnews3|SRIDHAR0520|StillAliveRicha|StreetBuzzApp|SuryanshiketSh3")
                    

```


```{r}
ind_screen <- ("SansaniPatrakar|rohitkr108|SiddharthaRai2|shia_channel|theiasindia|theindianminds|theindiapost1|JustaVoice1230|utpalschaudhary|ZennSays_|Rashida_Sial|ishubhambhatia|jatinbhutani92|KSMANN|SuparnaSharma|Hii_India|SYSCARE20|real_atta|whoskj2|Deepika81682230|withbjp4india|Itsak26|KajoriS|LijuMat21801891|lalithasundaram|KaustavB2|churumuri|jencyjac|naveengarewal|VidhyadharV|Swapnil_g23|syedgmurtaza|SyedIbr97161367|tagdef|takeonedigital|Tarique1391|TelangaanaBidda|IamMadhurendra|idattagupta|ihaveaview|ieDelhi|ImBrijeshsing|imfilmycom|ImmranKhalid|IMNnetwork10|ind2day|independentrep7|IndiaNe64115065|IndianNewsGuru|indiannewstv1|AapkaNews_in|heyjahan|Hii_India|hindi_vivek|Hindinewshubin|Hindu_Live|IAANGroup|infosecnews_|Inkhabar|inkl|iron_emu|ishubhambhatia|islamudinsajid|Itsak26|itvprashant|Jagadish_M|jahnavi_sen|jatinbhutani92|jayatrinMIRROR|jaypatel9491|jencyjac|jilajeetprajapa|johnnytorkustan|withbjp4india|maqbool_sm|SYSCARE20|swapnildwivedi4|HappeningNow__|KSMANN|krIshNDIA|whoskj2|Itsak26|Ferraodesigns|whoskj2|bhupendrachaube|nbtnavin0311|cgtop36|runku111|MSyedt|mohdvaseem01|SuparnaSharma|sadiakhurram|whoskj2|heyjahan|mohdvaseem01|tracyshilshi|cgtop36|Ms_jodha|Nspeaker95|Sundar_Ind|nerdmela|Hindu_Live|rakeshposwal|MaskManNews|sandarshikaa|GouravV38494306|pathak_praveen9|prepaidnewstra1|proud_bharat|QuickTake|Rajnishjee2|rakeshojjha|RakeshV24566992|Himansh59488582")

neutral_screennames <- c("indiatvnews","TheQuint","timesofindia","latestly","htTweets","Outlookindia","NH_India","TV9Bharatvarsh","news18dotcom","DeccanHerald","NewsNationTV", "TimesNow","firstpost","TheHansIndiaWeb","thetribunechd","htdelhi","ndtv","aajtak","FinancialXpress","IndiaToday","HappeningNow__","NBTDilli","Oneindia","IndianExpress","WFNhindi","BigYack_India","ANN_Newsable","Newskarnataka","mathrubhumieng","LogicalIndians","SakshiPost","digitalgoa","udayavani_web","NorthEastToday","thenews_intl","DeccanChronicle","pakistaninews","NewsWingNews","ANI","EastMojo","prabhasakshi","ie_chennai","NewsStateHindi","Onmanorama","PatrikaNews","PhilDeCarolis","news24tvchannel","barandbench","AsiavilleNews","indialegalmedia","IndiaAheadNews","HcnNewsOfficial","NedrickExpress","WebduniaHindi","TheFederal_in","sakaltimes","IndiaFolo","Live_Hindustan", "talentedindiaTN", "PunjabKesariCom", "newzviewzoffice", "rashtra_news", "prabhatkhabar", "NewIndianXpress", "NewscheckerIn", "dt_next", "ABPNews", "NewsroomPostCom", "jagran_samachar", "DBhaskarHindi", "WyrcanNews","hwnewsnetwork", "NewsJunctionOrg", "TheSecondAngle", "Dailyaddaa", "editorji", "HindiKhabar", "WeForNews", "IndianEra24x7", "Pioneer_TS_AP", "SirfNewsIndia", "netindian", "ttindia", "Bharat24NewsTV", "TimesMedia24", "Gauri_News", "NMFNewsOfficial", "newsforsocial", "JantantraTv", "rninational", "UPkesari", "punjabkesari", "dailynews360", "DainikBhaskar", "HSnewsLive", "primenewslivetv", "AapkaNews_in", "LI_NewsChannel", "LiveUKOnline","newsclickin", "ImphalFreePress", "NENowNews", "time8news", "TNT_Magazine", "Breaking_24X7", "BengalNewz", "Bangladesh_BN", "AAPInNews","scroll_in","ZeeNews", "news8_plus", "GetNewsd", "TheCitizen_News", "pakistani_news",  "AJENews",         "cbnews_",         "DA_DEMOCRATIC",   "gnnhdofficial" ,  "kashmirobserver", "ahmedabadmirror","IndiaNewsStream", "ummid"  ,     "thehawk",         "TelanganaToday",  "ET_Specials",     "post_asia"  ,    "TimesofNewsHUB" , "HindustanTimes", "jknewstoday" , "News18India",    "YuvNewsOfficial", "thewire_in" ,     "madhyamam" ,      "theupdaterpost",  "mail_today",   "Jansatta", "fpjindia"  ,"ani_digital","dna", "DKashmirimages",  "rouutnews" ,      "MSShanker1"   ,   "THP_India",       "DuniyaSamay",    "livemint"    ,    "NewsSalam",       "CNBCTV18News", "NewsLiveGhy",  "moneycontrolcom", "EINReligionNews", "RajneetiNews"  ,  "TodayViews",  "r__worldnews"  ,  "lhrtimes",        "pioneer_haryana", "TOIIndiaNews",    "TheStatesmanLtd", "MumbaiMirror" , "IEBengaluru"    , "NewsEverything_", "mellonpost"  ,    "theViralLines",   "krIshNDIA", "NI24NEWS",        "JudiciaryNews",   "gulftoday",       "HydYouthMirror", "legal_india" ,    "prudentgoa",      "THChennai" , "fasak24x7",    "vidyabox1",       "LatestN50378800", "Nh1News",        "fastnation_"  ,   "moviemoodnews",   "SundayGuardian" , "MSyedt"    ,"mohdvaseem01"  , "jayatrinMIRROR",  "KelungaJ" ,       "JAMMULINKS"  , "Punjabpress" ,    "GurungShauryaET", "Eastern_Mirror",  "ThePuneMirror",   "Openthemag",     "rohingya_update", "HRWTruth","NELiveTV", "THMumbai", "samaydhara",      "inkl",            "liveindianews18", "ForumStrategic",       "NewDelhiTimes")
```

Creating a training set - Tweet classification - Anti_CAA, Pro_CAA
```{r}
library(tidyverse)
#add pro and anti CAA column
caa_text <- caa_text %>% mutate("CAA_stance" = case_when(
  str_detect(hashtags, paste(anti_caa, collapse = "|")) ~ "Anti_CAA",
  str_detect(hashtags, paste(pro_caa, collapse = "|")) ~ "Pro_CAA"
   ))


#Number of Pro_CAA and Anti_CAA labelled tweets - 115,176 - 21% tweets are labelled.
table(caa_text$CAA_stance)

```

*Filter news organization from main dataset*

1. Filter out irrelevant tweets from news tweets 
2. Remove duplicated tweets from news deck
3. Total count of distinct tweets from news organisations - 6,286

```{r}

news_tweets <- caa_text %>% filter(str_detect(description, news_words)==TRUE) %>% distinct(text, .keep_all = TRUE)

#remove indvidual accounts from the news accounts  (Approximate cleaning)
news_tweets_dis <- news_tweets %>% filter(!str_detect(screen_name, ind_screen_name)==TRUE)

news_tweets_dis <- news_tweets_dis %>% filter(!str_detect(screen_name, ind_screen)==TRUE)

#Add the news/Not_news column to tweet columns
news_tweets_dis <- news_tweets_dis %>% mutate(news_notnews = "News")

#Add stance to the CAAstance column
news_tweets_dis <- news_tweets_dis %>% mutate("CAA_stance" = case_when(
  str_detect(hashtags, paste(anti_caa, collapse = "|")) ~ "Anti_CAA",
  str_detect(hashtags, paste(pro_caa, collapse = "|")) ~ "Pro_CAA",
  str_detect(screen_name, paste(neutral_screennames, collapse = "|")) ~ "Neutral"
   ))

```


```{r}

#Dataset containing "Distinct" "no-news org" tweets (Hopefully!)
citizen_tweets <- caa_text %>% filter(!text %in% news_tweets_dis$text) %>% distinct(text, .keep_all = TRUE)

#Remove useless tweets from the dataset
citizen_tweets <- citizen_tweets %>% filter(!str_detect(screen_name, "_cricketkeeda")==TRUE)

#Add extra news/not_news column to the dataset
citizen_tweets <- citizen_tweets %>% mutate(news_notnews = "Not News")

#22% tweets are labelled.
table(citizen_tweets$CAA_stance) 

table(citizen_tweets$lang) #More Hindi tweets than English tweets -> En:Hi : 44:56 ratio

```

*Dataset with -- Lang, Stance, News/NotNews columns* - 25% of the dataset is labelled - Neutral, Anti, Pro
```{r}

#Join the two datasets - news and citizen tweets 
caa <- rbind(citizen_tweets, news_tweets_dis) 

```

Step 1: Clean the text
```{r}
#Read the combined text file
caa <- fread("/Users/shreyaagarwal/Google Drive/Dissertation/Data/combined_news_citizen_tweets.csv", header = TRUE)

#caa <- caa[,-c(1,2)]

#Read the hindi stopwords file
hi_stop <- readLines("/Users/shreyaagarwal/Google Drive/Dissertation/Data/final_stopwords.txt", encoding = "UTF-8")

#Read hinglish stopwords file
hiEng_stop <- readLines("/Users/shreyaagarwal/Google Drive/Dissertation/Data/hinglish_stopwords.txt")

#devtools::install_github("quanteda/stopwords")


#Step 1: Scrub the text - hashtags, links, punctuation marks, stopwords, help words

caa$text <- as.character(caa$text)

caa$text <- gsub("<.*?>", "", caa$text) #get rid of stuff within brackets
caa$text <- gsub("http[[:alnum:][:punct:]]*", "", caa$text) #get rid of links and punctuation
caa$text <- str_replace_all(caa$text,"#[a-z,A-Z]*","") #get rid of hashtags
caa$text <- str_replace_all(caa$text,"@[a-z,A-Z]*","") #get rid of references of other screen names
caa$text = gsub("[[:punct:]]", "", caa$text) #get rid of punctuation
caa$text = gsub("[[:digit:]]", "", caa$text) #get rid of digits
caa$text <- str_replace_all(caa$text," "," ") #get rid of unncessary space
caa$text <- trimws(caa$text, "l")
```


```{r}

library(tidyverse)
library(data.table)

caa <- fread("/Users/shreyaagarwal/Google Drive/Dissertation/Data/combined_news_citizen_filtered.csv")


caa_english <- caa %>% filter(lang == "en")
caa_hi <- caa %>% filter(lang == "hi")

caa_hitext <- caa_hi[1:20000,] 
caa_hi_rest <- caa_hi[20001:129010,]

#was created because excel could not read the massive dataset. So, it was split into 20:80.
caa_halftext <- fread("/Users/shreyaagarwal/Downloads/hi_tweets_subtext - hi_tweets_subtext.csv")

#and then rbind-ed
caa_hindi <- rbind(caa_hi_rest,caa_halftext)

(caa_hindi$CAA_stance)

write_excel_csv(caa_english, "/Users/shreyaagarwal/Google Drive/Dissertation/Data/english_tweets.csv")

write.csv(caa_english, "/Users/shreyaagarwal/Google Drive/Dissertation/Data/english_tweets.csv", fileEncoding = "UTF-8")

write_excel_csv(caa_hindi, "/Users/shreyaagarwal/Google Drive/Dissertation/Data/hindi_tweets.csv")

write.csv(caa_hindi, "/Users/shreyaagarwal/Google Drive/Dissertation/Data/hi_tweets.csv")

s <- fread("/Users/shreyaagarwal/Google Drive/Dissertation/Data/hi_tweets.csv", header = TRUE)



```

```{r}


Hinews_tweets <- caa_hindi %>% filter(str_detect(description, news_words)==TRUE) %>% distinct(text, .keep_all = TRUE)

hicitizen_tweets <- caa_hindi %>% filter(!text %in% Hinews_tweets$text) %>% distinct(text, .keep_all = TRUE)

hindi_tweets <- rbind(Hinews_tweets, hicitizen_tweets)

library(openxlsx)
write.xlsx(hindi_tweets, "/Users/shreyaagarwal/Google Drive/Dissertation/Data/hi_tweets1.xlsx")
```

#Read english tweets and remove hashtags from it.
```{r}
eng_tweets <- read.csv("/Users/shreyaagarwal/Google Drive/Dissertation/Data/english_tweets123 copy.csv", header = TRUE)

eng_tweets$text <- str_replace_all(eng_tweets$text, "AmitShahIstifaDo", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "SaveDelhiHindus", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "IndiaAgainstCAANRC", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "UNRejectsCAA", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "CAA UNRejectsCAA", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "DelhiRiots2020 AmitShahIstifaDo", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "UNRejectsCAA UNRejectsCAA", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "Tahirhussainterrorist", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "UNRejectsCAA", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "IndiaAgainstCAA", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "ArrestKapilMishra", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "SCSTOBCAgainstHate", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "हिंदुओकोमारनाबंदकरो", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "ArrestTahirHussain", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "DelhiRiots2020", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "DelhiBurning", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "DelhiBurning ArrestTerroristKapilMishra", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "AntiHinduRiot", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "AntiHinduRiots", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "UN", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "mosque DelhiBurning ArrestTerroristKapilMishra", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "ArrestTerroristKapilMishra", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "WhyBJPBurningDelhi", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "GenocideInDelhi", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "ArrestSwaraBhaskar", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "AmitShahResign", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "DelhiAgainstJehadiViolence", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "DelhiRiotTruth", "")
eng_tweets$text <- str_replace_all(eng_tweets$text, "stopkillinghindus", "")

write.csv(eng_tweets, "/Users/shreyaagarwal/Google Drive/Dissertation/Data/english_tweets123 copy.csv", fileEncoding = "UTF-8")
```

#Read Hindi tweets and remove hashtags from it.
```{r}
Hindi_tweets <- read.xlsx("/Users/shreyaagarwal/Google Drive/Dissertation/Data/hi_tweets1.xlsx")
```

```{r}
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "AmitShahIstifaDo", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "SaveDelhiHindus", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "IndiaAgainstCAANRC", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "UNRejectsCAA", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "CAA UNRejectsCAA", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "DelhiRiots2020 AmitShahIstifaDo", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "UNRejectsCAA UNRejectsCAA", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "Tahirhussainterrorist", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "UNRejectsCAA", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "IndiaAgainstCAA", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "ArrestKapilMishra", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "SCSTOBCAgainstHate", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "हिंदुओकोमारनाबंदकरो", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "ArrestTahirHussain", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "DelhiRiots2020", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "DelhiBurning", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "DelhiBurning ArrestTerroristKapilMishra", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "AntiHinduRiot", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "AntiHinduRiots", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "UN", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "mosque DelhiBurning ArrestTerroristKapilMishra", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "ArrestTerroristKapilMishra", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "WhyBJPBurningDelhi", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "GenocideInDelhi", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "ArrestSwaraBhaskar", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "AmitShahResign", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "DelhiAgainstJehadiViolence", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "DelhiRiotTruth", "")
hindi_tweets$text <- str_replace_all(hindi_tweets$text, "stopkillinghindus", "")

```

```{r}
hindi_tweets$text <- gsub("<.*?>", "", hindi_tweets$text) #get rid of stuff within brackets
hindi_tweets$text <- gsub("http[[:alnum:][:punct:]]*", "", hindi_tweets$text) #get rid of links and punctuation
hindi_tweets$text <- str_replace_all(hindi_tweets$text,"#[a-z,A-Z]*","") #get rid of hashtags
hindi_tweets$text <- str_replace_all(hindi_tweets$text,"@[a-z,A-Z]*","") #get rid of references of other screen names
hindi_tweets$text = gsub("[[:punct:]]", "", hindi_tweets$text) #get rid of punctuation
hindi_tweets$text = gsub("[[:digit:]]", "", hindi_tweets$text) #get rid of digits
hindi_tweets$text <- str_replace_all(hindi_tweets$text," "," ") #get rid of unncessary space
hindi_tweets$text <- trimws(hindi_tweets$text, "l")

```

```{r}
write.csv(hindi_tweets,"/Users/shreyaagarwal/Google Drive/Dissertation/Data/hi_tweets1.csv")
```

